{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "The code of this notebook uses the combined \"GermanFakeNC\" and Fake \"News Dataset German\" to predict whether a given article is FakeNews or not. The labels are \"True\" for Fake News and \"False\" for Real News.\n",
    "\n",
    "There are 9 \"results\" in total:\n",
    "Three classifiers are used (Complement Naive Bayes, Logistic Regression and Random Forest), each one using three different representations of the input: \n",
    "\n",
    "A pure BOW representation (binary CountVectorizer)\n",
    "\n",
    "Word frequencies (CountVectorizer)\n",
    "\n",
    "tf.idf representations (TfidfVectorizer)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "from typing import Union\n",
    "from typing_extensions import Literal\n",
    "from scipy import sparse as sp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from spacy.lang.de.stop_words import STOP_WORDS\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix,ConfusionMatrixDisplay\n",
    "from sklearn.metrics import classification_report,accuracy_score,f1_score\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import ComplementNB #good for imbalanced data\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "RAND = 42 #random state\n",
    "N_CORES = 3 #number of CPU cores to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = pd.read_pickle(r\"datasets/combined.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_cmPlot(confusion_matrix,colour:Literal[\"Blues\",\"Greens\",\"Reds\"],title:str,filename:str):\n",
    "    fig = ConfusionMatrixDisplay(confusion_matrix=confusion_matrix,\n",
    "                                 display_labels=[\"Fake\",\"Legitimate\"])\n",
    "    fig = fig.plot(include_values=True,\n",
    "                    cmap=plt.cm.get_cmap(colour), \n",
    "                    ax=None, xticks_rotation=\"horizontal\")\n",
    "    fig.ax_.set_title(title)\n",
    "    plt.savefig(r\"plots/\"+filename,dpi=350)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_raw, X_test_raw, y_train, y_test = train_test_split(\n",
    "    raw_data[\"Body\"],\n",
    "    raw_data[\"Fake\"],\n",
    "    test_size=0.333,\n",
    "    random_state=RAND\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the \"default\" scenario set vec_args = dict():\n",
    "vec_args={\"stop_words\":STOP_WORDS,\"encoding\":\"utf-8\"}\n",
    "vectorizers = [\n",
    "        CountVectorizer(**vec_args,binary=True),    #pure BOW\n",
    "        CountVectorizer(**vec_args),\n",
    "        TfidfVectorizer(**vec_args)\n",
    "    ]\n",
    "# For the \"default\" scenario comment out the next two lines, but uncomment the third one:\n",
    "weights = {True:0.921,False:0.079} #inverse proportion of Fake News to Real News\n",
    "cls_args = {\"class_weight\":weights,\"random_state\":RAND,\"n_jobs\":N_CORES}\n",
    "# cls_args = {\"random_state\":RAND,\"n_jobs\":N_CORES}\n",
    "classifiers = [\n",
    "        ComplementNB(),\n",
    "        LogisticRegression(**cls_args,multi_class = \"ovr\"), #ovr used just so I can use \n",
    "                                                            #more than one core\n",
    "        RandomForestClassifier(**cls_args)\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "AVG_METHOD = \"micro\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1s  = dict() # (classifier,vectorizer) -> f1\n",
    "accs = dict() # ((classifier,vectorizer),\"class\") -> accuracy\n",
    "cms  = dict() # (classifier,vectorizer) -> confusion matrix\n",
    "for vectorizer in vectorizers:\n",
    "    Xtrain_vectors = vectorizer.fit_transform(X_train_raw)\n",
    "    Xtest_vectors  = vectorizer.transform(X_test_raw)\n",
    "    for classifier in classifiers:\n",
    "        experiment = (classifier,vectorizer)\n",
    "        #training\n",
    "        classifier.fit(Xtrain_vectors,y_train)\n",
    "        #testing\n",
    "        y_predictions = classifier.predict(Xtest_vectors)\n",
    "        \n",
    "        f1 = f1_score(y_test,y_predictions,average=AVG_METHOD)\n",
    "        f1s[experiment] = f1\n",
    "\n",
    "        cm = confusion_matrix(y_test,y_predictions,labels=[True,False])\n",
    "        accuracies = cm.diagonal()/cm.sum(axis=1)\n",
    "\n",
    "        cms[experiment] = cm\n",
    "\n",
    "        accs[experiment,\"Fake\"] = accuracies[0] #True\n",
    "        accs[experiment,\"Legitimate\"] = accuracies[1] #False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{(LogisticRegression(class_weight={False: 0.079, True: 0.921}, multi_class='ovr',\n",
       "                     n_jobs=3, random_state=42), CountVectorizer(binary=True,\n",
       "                  stop_words={'a', 'ab', 'aber', 'ach', 'acht', 'achte', 'achten',\n",
       "                              'achter', 'achtes', 'ag', 'alle', 'allein', 'allem',\n",
       "                              'allen', 'aller', 'allerdings', 'alles',\n",
       "                              'allgemeinen', 'als', 'also', 'am', 'an', 'andere',\n",
       "                              'anderem', 'anderen', 'andern', 'anders', 'auch',\n",
       "                              'auf', 'aus', ...})): 0.9900205319199733,\n",
       " (LogisticRegression(class_weight={False: 0.079, True: 0.921}, multi_class='ovr',\n",
       "                     n_jobs=3, random_state=42),\n",
       "  CountVectorizer(stop_words={'a', 'ab', 'aber', 'ach', 'acht', 'achte', 'achten',\n",
       "                              'achter', 'achtes', 'ag', 'alle', 'allein', 'allem',\n",
       "                              'allen', 'aller', 'allerdings', 'alles',\n",
       "                              'allgemeinen', 'als', 'also', 'am', 'an', 'andere',\n",
       "                              'anderem', 'anderen', 'andern', 'anders', 'auch',\n",
       "                              'auf', 'aus', ...})): 0.9885403237358544,\n",
       " (ComplementNB(),\n",
       "  CountVectorizer(stop_words={'a', 'ab', 'aber', 'ach', 'acht', 'achte', 'achten',\n",
       "                              'achter', 'achtes', 'ag', 'alle', 'allein', 'allem',\n",
       "                              'allen', 'aller', 'allerdings', 'alles',\n",
       "                              'allgemeinen', 'als', 'also', 'am', 'an', 'andere',\n",
       "                              'anderem', 'anderen', 'andern', 'anders', 'auch',\n",
       "                              'auf', 'aus', ...})): 0.963233538652533}"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "top3 = dict(sorted(f1s.items(),key=lambda x: x[1],reverse=True)[:3])\n",
    "top3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for experiment,f1 in top3.items():\n",
    "    classifier,vectorizer = experiment\n",
    "    clsifiername = classifier.__class__.__name__\n",
    "    vecrizername = vectorizer.__class__.__name__ \n",
    "    title = clsifiername + \\\n",
    "            \" with \" + \\\n",
    "            vecrizername + \\\n",
    "            (\"(binary)\" if vectorizer.binary else \"\")\n",
    "    save_cmPlot(cms[experiment],\n",
    "            colour=\"Reds\",\n",
    "            title=title,\n",
    "            filename=clsifiername+\"_\"+vecrizername+\\\n",
    "                (\"(binary)\" if vectorizer.binary else \"\")+\".png\"\n",
    "            )"
   ]
  },
  {
   "source": [
    "In the following, the classification will be performed on the titles. Only the best performing experiment will be used."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "CountVectorizer(binary=True,\n",
       "                stop_words={'a', 'ab', 'aber', 'ach', 'acht', 'achte', 'achten',\n",
       "                            'achter', 'achtes', 'ag', 'alle', 'allein', 'allem',\n",
       "                            'allen', 'aller', 'allerdings', 'alles',\n",
       "                            'allgemeinen', 'als', 'also', 'am', 'an', 'andere',\n",
       "                            'anderem', 'anderen', 'andern', 'anders', 'auch',\n",
       "                            'auf', 'aus', ...})"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "(best_clsifier,best_vecrizer),_ = \\\n",
    "    sorted(top3.items(),key=lambda x: x[1],reverse=True)[:1][0]\n",
    "best_vecrizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles_X_train, titles_X_test, titles_y_train, titles_y_test = \\\n",
    "    train_test_split(\n",
    "        raw_data[\"Title\"],\n",
    "        raw_data[\"Fake\"],   #True: Is Fake News, False: Isn't\n",
    "        test_size=0.333, \n",
    "        random_state=RAND \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calling these methods again will overwrite all previous progress (exactly what is needed):\n",
    "titles_Xtrain_vecs = best_vecrizer.fit_transform(titles_X_train)\n",
    "titles_Xtest_vecs  = best_vecrizer.transform(titles_X_test)\n",
    "#training\n",
    "best_clsifier.fit(titles_Xtrain_vecs,titles_y_train)\n",
    "#testing\n",
    "titles_y_predictions = best_clsifier.predict(titles_Xtest_vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_f1 = f1_score(y_test,y_predictions,average=AVG_METHOD)\n",
    "title_cm = confusion_matrix(titles_y_test,titles_y_predictions,labels=[True,False])\n",
    "title_accuracies = title_cm.diagonal()/title_cm.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "clsifiername = best_clsifier.__class__.__name__\n",
    "vecrizername = best_vecrizer.__class__.__name__ \n",
    "title =     clsifiername + \\\n",
    "            \" with \" + \\\n",
    "            vecrizername + \\\n",
    "            (\"(binary)\" if best_vecrizer.binary else \"\")\n",
    "save_cmPlot(title_cm,\n",
    "            colour=\"Greens\",\n",
    "            title=title,\n",
    "            filename=\"TITLE\"+clsifiername+\"_\"+vecrizername+\\\n",
    "                (\"(binary)\" if vectorizer.binary else \"\")+\".png\"\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "titledict = {\n",
    "    \"Title Classifier\": best_clsifier,\n",
    "    \"Title Vectorizer\": best_vecrizer,\n",
    "    \"Title F1\":         title_f1,\n",
    "    \"Acc Fake\":         title_accuracies[0],\n",
    "    \"Acc Legitimate\":   title_accuracies[1]\n",
    "}\n",
    "from pprint import pformat\n",
    "with open(r\"detection_metrics.txt\",\"w\",encoding=\"utf-8\") as f:\n",
    "    print(\"Article Bodies:\",\n",
    "          \"F1s:\",\n",
    "          pformat(f1s),\n",
    "          \"Accuracies:\",\n",
    "          pformat(accs),\n",
    "          \"-------------\",\n",
    "          \"Titles:\",\n",
    "          pformat(titledict),\n",
    "          sep=\"\\n\",file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}